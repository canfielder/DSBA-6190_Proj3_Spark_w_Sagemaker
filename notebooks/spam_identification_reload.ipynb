{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "spam_identification_reload.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4spfRZVl3yIl",
        "cITX1X0k3yIl",
        "UtRkqws93yIl",
        "p9odfw7n3yIm",
        "9mwYzY3S3yIo",
        "39wfYT633yIp",
        "HFkmGTCj3yIp",
        "3StIz-H13yIq",
        "72JYXJUf3yIq",
        "jJHUwLsd3yIq"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsLjCtv-3yIM"
      },
      "source": [
        "# Overview\n",
        "This notebook developes a Spam message identification model using pyspark in an AWS Sagemaker evironment. The dataset for this model is the UCI SMS Spam Collection Data Set found [here](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection). While this dataset is small, the problem this notebook addresses, Spam messages, is a problem that encompasses large enough amounts of data to be a task suited for the Spark platform. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UxGkm083yIW"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC9BxZxo3yIW"
      },
      "source": [
        "## Packages / Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JOfhXc139X5"
      },
      "source": [
        "import re\r\n",
        "import os\r\n",
        "import boto3\r\n",
        "from functools import reduce\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import itertools\r\n",
        "\r\n",
        "import sagemaker\r\n",
        "import sagemaker_pyspark\r\n",
        "from sagemaker import get_execution_role\r\n",
        "\r\n",
        "from pyspark import SparkContext, SparkConf\r\n",
        "from pyspark.ml import Pipeline\r\n",
        "from pyspark.ml.classification import LogisticRegression\r\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator,\\\r\n",
        "                                  BinaryClassificationEvaluator\r\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, \\\r\n",
        "                               HashingTF, IDF\r\n",
        "from pyspark.ml.linalg import VectorUDT\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "import pyspark.sql.functions as f\r\n",
        "from pyspark.sql.functions import udf\r\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType,\\\r\n",
        "                              IntegerType, StringType\r\n",
        "\r\n",
        "from sagemaker_pyspark import RandomNamePolicyFactory, IAMRole,\\\r\n",
        "                              EndpointCreationPolicy, SageMakerModel,\\\r\n",
        "                              SageMakerResourceCleanup\r\n",
        "from sagemaker_pyspark.algorithms import XGBoostSageMakerEstimator,\\\r\n",
        "                                         PCASageMakerEstimator\r\n",
        "from sagemaker_pyspark.transformation.serializers \\\r\n",
        "     import ProtobufRequestRowSerializer\r\n",
        "from sagemaker_pyspark.transformation.serializers.serializers \\\r\n",
        "     import LibSVMRequestRowSerializer\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\r\n",
        "\r\n",
        "# Set Seed for Random Actions\r\n",
        "seed = 5590"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asc7-Qqe3yIX"
      },
      "source": [
        "## Setup AWS and Spark\n",
        "The following code blocks set up the global values and settings for AWS and Spark parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6I2P7K93yIY"
      },
      "source": [
        "### AWS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otwJmT1d3yIY"
      },
      "source": [
        "role = get_execution_role()\n",
        "bucket = \"dsba-6190-project3-spark\"\n",
        "file_name = \"spam.csv\"\n",
        "session = sagemaker.Session()\n",
        "region = boto3.Session().region_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGq6OCal3yIY"
      },
      "source": [
        "### Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK56xGyS3yIY"
      },
      "source": [
        "# Configure Spark to use the SageMaker Spark dependency jars\n",
        "jars = sagemaker_pyspark.classpath_jars()\n",
        "\n",
        "classpath = \":\".join(sagemaker_pyspark.classpath_jars())\n",
        "\n",
        "spark = SparkSession.builder.config(\"spark.driver.extraClassPath\", classpath)\\\n",
        "    .master(\"local\")\\\n",
        "    .appName(\"Spam Filter\")\\\n",
        "    .getOrCreate()\n",
        "    \n",
        "spark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mza57p-e3yIZ"
      },
      "source": [
        "## Load Data\n",
        "When we try to load the data using default settings, the import adds headers and includes several empty columns. To avoid this, we define the schema of the data before we import."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uanhg-C3yIZ"
      },
      "source": [
        "# Define Known Schema\n",
        "schema = StructType([\n",
        "    StructField(\"class\", StringType()),\n",
        "    StructField(\"sms\", StringType())\n",
        "])\n",
        "\n",
        "# Import CSV\n",
        "df = spark.read\\\n",
        "          .schema(schema)\\\n",
        "          .option(\"header\", \"true\")\\\n",
        "          .csv('s3a://{}/{}'.format(bucket, file_name))\n",
        "\n",
        "df_num_col =  len(df.columns)\n",
        "df_num_rows = df.count()\n",
        "\n",
        "# Inspect Import\n",
        "df.show(5)\n",
        "print()\n",
        "print(\"Schema\")\n",
        "df.printSchema()\n",
        "print()\n",
        "print(\"Shape - Rows x Columns\")\n",
        "print(df_num_rows,\"x\", df_num_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKdRpvvw3yIZ"
      },
      "source": [
        "#### Check Null Values\n",
        "We need to check and see if our data contains any null values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAPbMA6H3yIa"
      },
      "source": [
        "df.where(reduce(lambda x, y: x | y, (f.col(x).isNull() \\\n",
        "                                     for x in df.columns))).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yntNxFFh3yIa"
      },
      "source": [
        "It appears one of the rows contains null values, and the class label is corrupted as well. We can go ahead and drop this row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJnXleFT3yIa"
      },
      "source": [
        "df = df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdUMhza13yIa"
      },
      "source": [
        "Lets now inspect the dataframe now that the null row has been dropped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReF8ERzt3yIb"
      },
      "source": [
        "df_num_col =  len(df.columns)\n",
        "df_num_rows = df.count()\n",
        "\n",
        "# Inspect Import\n",
        "df.show(5)\n",
        "print()\n",
        "print(\"Schema\")\n",
        "df.printSchema()\n",
        "print()\n",
        "print(\"Shape - Rows x Columns\")\n",
        "print(df_num_rows,\"x\", df_num_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59wIA_kl3yIb"
      },
      "source": [
        "Re-check null values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVISi2tT3yIb"
      },
      "source": [
        "df.where(reduce(lambda x, y: x | y, (f.col(x).isNull() \\\n",
        "                                     for x in df.columns))).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2xekSQF3yIb"
      },
      "source": [
        "# EDA\n",
        "We'll do some very basic EDA here. First we'll look at the breakdown of our target variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLL1Yzm63yIb"
      },
      "source": [
        "df.groupBy(\"class\").count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1w3yqKr3yIc"
      },
      "source": [
        "Clearly there is an error with the class label on one value. Lets see what the message is associated with **ham\"\"\"**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ff2SA933yIc"
      },
      "source": [
        "df.where(f.col(\"class\") == 'ham\"\"\"').show(truncate = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLl0RelJ3yIc"
      },
      "source": [
        "This doesn't seem out of the oridinary, and appears to be a **ham** sms message. I am going to change **ham\"\"\"** to **ham**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8z3Et_n3yIc"
      },
      "source": [
        "df = df.withColumn(\"class\", f.when(f.col(\"class\") == 'ham\"\"\"' , 'ham').\n",
        "                     otherwise(f.col(\"class\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxNAghzR3yIc"
      },
      "source": [
        "Lets verify the change occurred."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tEID9uM3yId"
      },
      "source": [
        "df.groupBy(\"class\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk1ilaNo3yId"
      },
      "source": [
        "# Preprocess\n",
        "Before we perform any analysis on the data we will need to perform three major steps:\n",
        "\n",
        "1. Text Normalization\n",
        "2. Tokenization \n",
        "3. TF-IDF Transformation\n",
        "\n",
        "With Text Normalization, we will process the raw text to provide a quality input for our model. These actions used the blog post [**Spam classification using Spark’s DataFrames, ML and Zeppelin (Part 1)**](https://blog.codecentric.de/en/2016/06/spam-classification-using-sparks-dataframes-ml-zeppelin-part-1/) by Daniel Pape, accessed on 4/16/2020, as guidance for some of these actions. This blog post provided a good framework particularly for handling types of text you find in an SMS message, such as emoticons.\n",
        "\n",
        "Once the raw text is normalized, we can then tokenize and convert the text into a form that can be used by the analytical model.\n",
        "\n",
        "## Text Normalization\n",
        "To normalize the text, there are several steps we plan on taking:\n",
        "\n",
        "1. Convert all text to lowercase\n",
        "2. Convert all numbers to the text **_\" normalized_number \"_**\n",
        "3. Convert all emoticons to the text **_\" normalized_emoticon \"_**\n",
        "4. Convert all currency symbols to the text **_\" normalized_currency_symbol \"_**\n",
        "5. Convert all links to the text **_\" normalized_url \"_**\n",
        "6. Convert all email addresses to the text **_\" normalized_email \"_**\n",
        "7. Convert all diamond/question mark symbols to the text **_\" normalized_doamond_symbol \"_**\n",
        "8. Remove HTML characters\n",
        "9. Remove punctuation\n",
        "\n",
        "### Convert Text to Lower Case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CvV8yI93yIe"
      },
      "source": [
        "df_norm = df.select(\"class\",\"sms\", f.lower(f.col(\"sms\")).alias(\"sms_norm\"))\n",
        "df_norm.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O2O65EF3yIe"
      },
      "source": [
        "### Normalize Symbols and Objects\n",
        "To normalize the symbols and objects in the data, we will need to define user functions and employ replacement with regex tools.\n",
        "\n",
        "To enable a method to cycle through the dataframe and make all the necessary replacements, I am going to define a dictionary, where each key is the expression that will be used to find what needs to be replaces, and the value is the repalcement string.\n",
        "\n",
        "The regex for the emoticons came from [here](https://www.regextester.com/96995).\n",
        "\n",
        "The remaining regex expressions came from [here](https://github.com/daniel-pape/spark-logistic-regression-spam-sms/blob/master/src/main/scala/preprocessing/LineCleaner.scala)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E55IS42u3yIe"
      },
      "source": [
        "html_list = [\"&lt;\", \"&gt;\", \"&amp;\", \"&cent;\", \"&pound;\", \"&yen;\", \"&euro;\", \"&copy;\", \"&reg;\"]\n",
        "\n",
        "regex_url = \"\\\\w+(\\\\.|-)*\\\\w+@.*\\\\.(com|de|uk)\"\n",
        "regex_emoticon = \":\\)|:-\\)|:\\(|:-\\(|;\\);-\\)|:-O|8-|:P|:D|:\\||:S|:\\$|:@|8o\\||\\+o\\(|\\(H\\)|\\(C\\)|\\(\\?\\)\"\n",
        "regex_number = \"\\\\d+\"\n",
        "regex_punctuation =\"[\\\\.\\\\,\\\\:\\\\-\\\\!\\\\?\\\\n\\\\t,\\\\%\\\\#\\\\*\\\\|\\\\=\\\\(\\\\)\\\\\\\"\\\\>\\\\<\\\\/]\"\n",
        "regex_currency = \"[\\\\$\\\\€\\\\£]\"\n",
        "regex_url =  \"(http://|https://)?www\\\\.\\\\w+?\\\\.(de|com|co.uk)\"\n",
        "regex_diamond_question = \"�\"\n",
        "regex_html = \"|\".join(html_list)\n",
        "\n",
        "dict_norm = {\n",
        "    regex_emoticon : \" normalized_emoticon \",\n",
        "    regex_url : \" normalized_emailaddress \",\n",
        "    regex_number : \" normalized_number \",\n",
        "    regex_punctuation : \" \",\n",
        "    regex_currency : \" normalized_currency_symbol \",\n",
        "    regex_url: \" normalized_url \",\n",
        "    regex_diamond_question : \" normalized_doamond_symbol \",\n",
        "    regex_html : \" \"\n",
        "}\n",
        "\n",
        "for key, value in dict_norm.items():\n",
        "    df_norm = df_norm.withColumn(\"sms_norm\", f.regexp_replace(f.col(\"sms_norm\"), key, value))\n",
        "\n",
        "    df_norm.select('class','sms_norm').show(5, truncate = False)\n",
        "\n",
        "df = df_norm.dropna()\n",
        "\n",
        "print(\"Shape - Rows x Columns\")\n",
        "print(df.count(),\"x\", len(df.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx4nu1hh3yIg"
      },
      "source": [
        "We're going to check again for null values, to ensure the conversion hasn't created any new null values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QOM6Ljf3yIg"
      },
      "source": [
        "df = df_norm\n",
        "df.where(reduce(lambda x, y: x | y, (f.col(x).isNull() \\\n",
        "                                     for x in df.columns))).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rZF-a8G3yIh"
      },
      "source": [
        "## Convert Class to Binary\n",
        "We need to convert our spam/ham class to a binary. We also need to conert the column type to int."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjWHxHyp3yIh"
      },
      "source": [
        "df_norm = df_norm.withColumn(\"class\", f.when(f.col(\"class\") == \"spam\" , 1).\n",
        "                             when(f.col(\"class\") == \"ham\" , 0).\n",
        "                             otherwise(f.col(\"class\")))\n",
        "\n",
        "df_norm = df_norm.withColumn(\"class\", f.col('class').cast(IntegerType()))\n",
        "df_norm.show(5)\n",
        "df_norm.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6KL_R0Z3yIi"
      },
      "source": [
        "## Text Tokenization and Transformation\n",
        "We will tokenize the text using a pyspark pipeline. First, we must initialize the pipeline components. For this pipeline, we will user the following estimators:\n",
        "\n",
        "1. Tokenizer\n",
        "2. Stop Words Remover\n",
        "3. Term Frequency Hashing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOVNo0QU3yIi"
      },
      "source": [
        "### Establish Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQPRCuQc3yIi"
      },
      "source": [
        "tokenizer = Tokenizer(inputCol=\"sms_norm\", outputCol=\"tokens\")\n",
        "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_filtered\")\n",
        "hashingTF = HashingTF(inputCol=\"tokens\", outputCol=\"features_tf\", \n",
        "                      numFeatures=1000)\n",
        "\n",
        "pipeline_text = Pipeline(stages=[tokenizer, remover, hashingTF])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fRztSrQ3yIi"
      },
      "source": [
        "### Execute Pipeline on Complete Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2-e3oYg3yIj"
      },
      "source": [
        "pipeline_text_fit = pipeline_text.fit(df_norm)\n",
        "df_pipeline = pipeline_text_fit.transform(df_norm)\n",
        "df_pipeline.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8Ap0xLP3yIj"
      },
      "source": [
        "## Train / Test Split\n",
        "Now that we have performed all the possible actions that should be performed on the complete dataset, we split the data into train/test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5xNy_ZE3yIj"
      },
      "source": [
        "split_train = 0.8\n",
        "train, test = df_pipeline.randomSplit([split_train, (1-split_train)], seed=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSJZKTLD3yIj"
      },
      "source": [
        "### Verify Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvfyBDWQ3yIj"
      },
      "source": [
        "print(\"Shape - Train\")\n",
        "print((train.count(), len(train.columns)))\n",
        "print()\n",
        "print(\"Shape - Test\")\n",
        "print((test.count(), len(test.columns)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoqWxwxh3yIk"
      },
      "source": [
        "## Inverse Document Frequency Calculation\n",
        "To calculate the Term Frequency - Inverse Document Frequency values for the corpus, we need to train the IDF estmator on the **train** data. Then we apply the trained estimator to the train and test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfq36aL13yIk"
      },
      "source": [
        "# Initialize IDF Estimator\n",
        "idf = IDF(minDocFreq=2, inputCol=\"features_tf\", outputCol=\"features_tfidf\")\n",
        "\n",
        "# Train IDF Estimator to Term Frequency Data\n",
        "idfModel = idf.fit(train)\n",
        "\n",
        "# Re-Scale Term Frequency Data \n",
        "train = idfModel.transform(train)\n",
        "test = idfModel.transform(test)\n",
        "\n",
        "# Inspect\n",
        "train.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hApLFit63yIk"
      },
      "source": [
        "## Isolate Data\n",
        "Moving forward we only need the tf-idf features and the class label. We will relabel them features and label to be consistent with the XGBoost Estmator input labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64Snrupl3yIk"
      },
      "source": [
        "df_train = train.select(f.col(\"class\").alias(\"label\"), f.col(\"features_tfidf\").\n",
        "                        alias(\"features\"))\n",
        "\n",
        "df_test = test.select(f.col(\"class\").alias(\"label\"), f.col(\"features_tfidf\").\n",
        "                      alias(\"features\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3iPUhi23yIk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBJuNgvh3yIk"
      },
      "source": [
        "# Train\n",
        "We will be training our data on the Sagemaker Pyspark XGBoost algorithm. One tricky part about using this algorithm is that it only takes **LIBSVM** format data. Unfortunatley, that is not the current format of our data. In order for the algoritm to accept our data as an input, we need to do three things\n",
        "\n",
        "1. Define the correct shema\n",
        "2. Convert data to match the correct schema\n",
        "3. Include **LibSVMRequestRowSerializer** as a parameter when initializing the XGBoost estimator.\n",
        "\n",
        "## Define the Schema\n",
        "In order to be accepted as a **LIBSVM** type data, the schema of our pyspark DataFrame must be a specific schema. The schema can be seen buried in the source code of the **Verify Schema** call in the **LibSVMRelation.scala** utility, see [here](https://github.com/apache/spark/blob/930b90a84871e2504b57ed50efa7b8bb52d3ba44/mllib/src/main/scala/org/apache/spark/ml/source/libsvm/LibSVMRelation.scala#L79) (accessed 4/17/2020). Based on this function, our data needs to be in two columns, one column a **DoubleType()** (which will be our label column) and the other column a **VectorUDT()** type (which will be our Sparse Vector features column). \n",
        "\n",
        "With these requirements, we define a general schema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfp0rwkF3yIk"
      },
      "source": [
        "schema = StructType([\n",
        "    StructField(\"label\", DoubleType()),\n",
        "    StructField(\"features\", VectorUDT())\n",
        "])\n",
        "print(schema)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4spfRZVl3yIl"
      },
      "source": [
        "## Convert Data to Match Schema\n",
        "We also convert the data types of our current train and test data sets to match this data type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBok0I-63yIl"
      },
      "source": [
        "#Train\n",
        "df_train = df_train.withColumn(\"label\", f.col('label').cast(DoubleType()))\n",
        "df_train = df_train.withColumn(\"features\", f.col('features').cast(VectorUDT()))\n",
        "print(\"Schema - Train\")\n",
        "df_train.printSchema()\n",
        "print()\n",
        "\n",
        "# Test\n",
        "df_test = df_test.withColumn(\"label\", f.col('label').cast(DoubleType()))\n",
        "df_test = df_test.withColumn(\"features\", f.col('features').cast(VectorUDT()))\n",
        "print(\"Schema - Test\")\n",
        "df_test.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cITX1X0k3yIl"
      },
      "source": [
        "## Initialize Model\n",
        "We will now initialize the XGBoost Estimator. A few notes:\n",
        "\n",
        "* In order for the estimator to accept our input data as **LIBSVM**, we need to use the parameter **requestRowSerializer**. We define this parameter as **LibSVMRequestRowSerializer**, identifying the feature column, label column, and schema. \n",
        "* This is personal preference, but I like adding name to the mode we're creating. It makes it easier to find when you're looking up past trained models. So we add a **namPolicyFactory** value. But be careful. If you want to deploy your model as an endpoint, the maximum number of characters the model name can have is 63. This means the prefix you add to the front of your model can only be about 10 characters. Sagemaker will tack-on the rest of the model tag. If you exceed 63 characters, deploying your endpoint will fail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAgJ92Ic3yIl"
      },
      "source": [
        "xgboost_estimator = XGBoostSageMakerEstimator(\n",
        "  sagemakerRole = IAMRole(role),\n",
        "  requestRowSerializer=LibSVMRequestRowSerializer(schema=schema,\n",
        "                                                 featuresColumnName=\"features\",\n",
        "                                                 labelColumnName=\"label\"),\n",
        "  trainingInstanceType = \"ml.m4.xlarge\",\n",
        "  trainingInstanceCount = 1,\n",
        "  endpointInstanceType = \"ml.m4.xlarge\",\n",
        "  endpointInitialInstanceCount = 1,\n",
        "  namePolicyFactory=RandomNamePolicyFactory(\"spam-xgb-\"),\n",
        "  endpointCreationPolicy = EndpointCreationPolicy.CREATE_ON_TRANSFORM\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtRkqws93yIl"
      },
      "source": [
        "## Set Hyperparameters\n",
        "After initializing the model, we set the hyperparameters. This problem is a binary classification problem, so we'll et the objective to **binary:logistic** and evaluate based on the **AUC** score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kYeincl3yIm"
      },
      "source": [
        "xgboost_estimator.setNumRound(15)\n",
        "xgboost_estimator.setObjective(\"binary:logistic\")\n",
        "xgboost_estimator.setEvalMetric(\"auc\")\n",
        "xgboost_estimator.setSeed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9odfw7n3yIm"
      },
      "source": [
        "## Train\n",
        "With everything set, we can now train the mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kygR5lbO3yIm"
      },
      "source": [
        "model = xgboost_estimator.fit(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDyDN6xC3yIm"
      },
      "source": [
        "# Evaluate\n",
        "## Transform\n",
        "First, we generate predictons based off the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGQcyMcm3yIn"
      },
      "source": [
        "predictions = model.transform(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ErIUxh53yIn"
      },
      "source": [
        "Then, we will assign predicted labels, using 0.5 as a threshold.\n",
        "\n",
        "We will also create re-labeled columns with spam and ham. This will be primarily for downstream visuals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-OhJiHZ3yIn"
      },
      "source": [
        "predictions = predictions.withColumn(\"prediction_binary\", \\\n",
        "                                     f.when(f.col(\"prediction\") > 0.5 , 1.0).\n",
        "                                     otherwise(0.0))\n",
        "\n",
        "predictions = predictions.withColumn(\"prediction_spam\", \\\n",
        "                                     f.when(f.col(\"prediction_binary\") == 1 ,\\\n",
        "                                            \"spam\").otherwise(\"ham\"))\n",
        "\n",
        "predictions = predictions.withColumn(\"label_spam\",\\\n",
        "                                     f.when(f.col(\"label\") == 1 , \"spam\").\n",
        "                                     otherwise(\"ham\"))\n",
        "predictions.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZXyCPpR3yIn"
      },
      "source": [
        "Lets take a look at the predicted distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuRepI-A3yIo"
      },
      "source": [
        "predictions.groupBy(\"prediction_spam\").count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mwYzY3S3yIo"
      },
      "source": [
        "### Scores\n",
        "Now we can look at some of the classification scores. Note that we are using both the **MulticlassClassificationEvaluator** and **BinaryClassificationEvaluator** objects to generate the metrics we want. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIBybz5k3yIo"
      },
      "source": [
        "def output_scores(predictions):\n",
        "    digit_format  = \": {:.4f}\"\n",
        "    \n",
        "    ### Multi-Class Evaluator\n",
        "    dict_metric_multi = {\"Accuracy\" : \"accuracy\", \n",
        "                         \"Precision - Weighted\" : \"weightedPrecision\", \n",
        "                         \"Recall - Weighted\" : \"weightedRecall\",\n",
        "                         \"F1 Score\": \"f1\"}\n",
        "\n",
        "    for key, value in dict_metric_multi.items():\n",
        "        evaluator =  MulticlassClassificationEvaluator(labelCol=\"label\", \n",
        "                                                   predictionCol=\\\n",
        "                                                       \"prediction_binary\", \n",
        "                                                   metricName=value)\n",
        "\n",
        "        metric = evaluator.evaluate(predictions)\n",
        "\n",
        "        print(key + digit_format.format(metric))   \n",
        "    \n",
        "    # Binary Class Evaluator\n",
        "    dict_metric_bin = {\"AUC Score\" : \"areaUnderROC\"}\n",
        "    for key, value in dict_metric_bin.items():\n",
        "    \n",
        "        evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
        "                                                  labelCol=\"label\", \n",
        "                                                  metricName=value)\n",
        "        \n",
        "        metric = evaluator.evaluate(predictions)\n",
        "        print(key + digit_format.format(metric))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg3rEpCb3yIo"
      },
      "source": [
        "output_scores(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39wfYT633yIp"
      },
      "source": [
        "## ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-OSjnmF3yIp"
      },
      "source": [
        "test_label = predictions.select('label').toPandas()\n",
        "test_pred = predictions.select('prediction').toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E-4AD-u3yIp"
      },
      "source": [
        "fpr, tpr, thresholds = roc_curve(test_label, test_pred)\n",
        "roc_auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqP0UMCe3yIp"
      },
      "source": [
        "roc_auc = auc(fpr, tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spNlzatZ3yIp"
      },
      "source": [
        "plt.rc('font', size=19.5) \n",
        "plt.figure(figsize=[7,7])\n",
        "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % (roc_auc))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFkmGTCj3yIp"
      },
      "source": [
        "## Confusion Matrix\n",
        "We are going to visualize the confusion matrix using the method outlined [here](https://runawayhorse001.github.io/LearningApacheSpark/classification.html#demo).\n",
        "### Confusion Matrix Plotting Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7BITPB53yIp"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        #print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print()\n",
        "        #print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.3f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3StIz-H13yIq"
      },
      "source": [
        "### Define Class Names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdkCb1T13yIq"
      },
      "source": [
        "# Create List of Class Names\n",
        "class_label = predictions.select(\"label_spam\").groupBy(\"label_spam\")\\\n",
        "    .count().sort('count', ascending=False).toPandas()\n",
        "class_names = class_label[\"label_spam\"].to_list()\n",
        "class_names\n",
        "#class_names = list(map(str, class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72JYXJUf3yIq"
      },
      "source": [
        "### Generate Raw Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwPR5yyr3yIq"
      },
      "source": [
        "# Convert Labels to Pandas Dataframe\n",
        "y_true = predictions.select(\"label_spam\")\n",
        "y_true = y_true.toPandas()\n",
        "\n",
        "# Convert Predictions to Pandas Dataframe\n",
        "y_pred = predictions.select(\"prediction_spam\")\n",
        "y_pred = y_pred.toPandas()\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJHUwLsd3yIq"
      },
      "source": [
        "### Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owHzPLHJ3yIr"
      },
      "source": [
        "plt.figure(figsize=[7,7])\n",
        "plot_confusion_matrix(cm, \n",
        "                      classes=class_names,\n",
        "                      normalize=True,\n",
        "                      title='Confusion Matrix, \\nWith Normalization')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecyeaekx3yIr"
      },
      "source": [
        "# Clean-Up\n",
        "After everything is done, we do not wan't to leave resources needlessly running, costing us money. So, we shut everything down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK-xQz0p3yIr"
      },
      "source": [
        "resource_cleanup = SageMakerResourceCleanup(model.sagemakerClient)\n",
        "resource_cleanup.deleteResources(model.getCreatedResources())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}